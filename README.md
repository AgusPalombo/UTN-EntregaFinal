# üß≠ Manual de Ejecuci√≥n ‚Äî Trabajo Final Grupo O (JupyterLab)

Este documento explica **c√≥mo ejecutar correctamente el archivo `TrabajoFinal_GrupoO.ipynb`** paso a paso, tanto en **JupyterLab**, **VS Code**, como en **Google Colab**.  

El notebook desarrolla un flujo completo de **an√°lisis de datos y machine learning** sobre el dataset **IBM HR Analytics Employee Attrition**, que puede descargarse desde Kaggle.

---

## ‚öôÔ∏è Requisitos e instalaci√≥n de dependencias

El proyecto requiere las siguientes librer√≠as de Python, listadas en el archivo **`requirements.txt`**.

Para instalarlas autom√°ticamente, ejecutar en una terminal (desde la carpeta del proyecto):

```bash
pip install -r requirements.txt
```

### üí° En caso de no tener instalado JupyterLab o las librer√≠as necesarias:
Ejecutar los siguientes comandos manualmente:

```bash
pip install pandas numpy matplotlib seaborn scikit-learn imbalanced-learn jupyterlab ipykernel
```

Una vez completada la instalaci√≥n, se podr√° abrir y ejecutar el notebook sin inconvenientes.

---

## üì¶ 1. Descargar el dataset

**Dataset oficial:**
üëâ [IBM HR Analytics Employee Attrition Dataset ‚Äî Kaggle](https://www.kaggle.com/datasets/pavansubhasht/ibm-hr-analytics-attrition-dataset/data)

Una vez descargado, obtendr√°s un archivo llamado:

```
WA_Fn-UseC_-HR-Employee-Attrition.csv
```

### Recomendaci√≥n:
- Crear una carpeta llamada `data` dentro del proyecto.  
- Colocar all√≠ el archivo CSV descargado.  
  Ejemplo:
  ```
  /TrabajoFinal_GrupoO/
  ‚îú‚îÄ‚îÄ data/
  ‚îÇ   ‚îî‚îÄ‚îÄ WA_Fn-UseC_-HR-Employee-Attrition.csv
  ‚îî‚îÄ‚îÄ TrabajoFinal_GrupoO.ipynb
  ```

---

## üß∞ 2. Abrir y ejecutar el notebook

Pod√©s abrir el archivo de tres maneras:

### üîπ Opci√≥n A ‚Äî **JupyterLab**
```bash
jupyter lab
```
Luego abr√≠ `TrabajoFinal_GrupoO.ipynb` y seleccion√°  
**Kernel ‚Üí Restart Kernel and Run All Cells** (para ejecutar todo autom√°ticamente).

### üîπ Opci√≥n B ‚Äî **VS Code**
1. Abr√≠ la carpeta del proyecto.  
2. Asegurate de tener instalada la extensi√≥n **Python** y **Jupyter**.  
3. Abr√≠ el archivo `.ipynb`.  
4. Pod√©s ejecutar celda por celda o con **Run All** (bot√≥n ‚ñ∂Ô∏è arriba del notebook).

### üîπ Opci√≥n C ‚Äî **Google Colab**
- Sub√≠ el archivo `.ipynb` a tu Google Drive.  
- Abrilo con Google Colab.  
- Sub√≠ el dataset o conect√° tu Drive para leerlo desde `/content/drive/MyDrive/...`.

---

## üß© 3. Orden recomendado de ejecuci√≥n (si no us√°s "Run All")

Si prefer√≠s ejecutar manualmente las celdas una por una, segu√≠ este orden:

### **Paso 1 ‚Äî Importaci√≥n de librer√≠as**
Ejecut√° la primera celda con los `import` de librer√≠as (`pandas`, `numpy`, `matplotlib`, `seaborn`, `sklearn`, etc.).  
Esto carga las dependencias necesarias.

---

### **Paso 2 ‚Äî Carga del dataset**
El notebook carga el archivo CSV principal.  
Asegurate de que la ruta del archivo est√© correctamente configurada.

Si necesit√°s **cambiar la ruta manualmente**, segu√≠ estos pasos:

1. En **VS Code** o el Explorador de archivos, hac√© clic derecho sobre el archivo CSV.  
2. Seleccion√° **‚ÄúCopiar ruta‚Äù** (o ‚ÄúCopy Path‚Äù).  
3. Peg√° esa ruta en el c√≥digo, por ejemplo:

```python
import pandas as pd
df = pd.read_csv(r"C:\Users\TuUsuario\Desktop\TrabajoFinal_GrupoO\data\WA_Fn-UseC_-HR-Employee-Attrition.csv")
```

> ‚ö†Ô∏è Asegurate de mantener la `r` antes de las comillas para evitar errores con las barras invertidas en Windows.

---

### **Paso 3 ‚Äî Exploraci√≥n inicial (EDA)**
Aqu√≠ se analizan las columnas, tipos de datos, valores nulos, estad√≠sticas y visualizaciones iniciales del dataset.

- Uso de `df.info()`, `df.describe()`, `df.isna().sum()`  
- Gr√°ficos exploratorios con `seaborn` y `matplotlib`

---

### **Paso 4 ‚Äî Proceso ETL (Limpieza y transformaci√≥n)**
En esta secci√≥n se:
- Elimina o rellena valores faltantes.  
- Convierte variables categ√≥ricas a num√©ricas (One-Hot Encoding).  
- Escala o normaliza variables num√©ricas (StandardScaler).  
- Divide el dataset en **features (X)** y **target (y)**.  
- Realiza el `train_test_split`.

---

### **Paso 5 ‚Äî Manejo del desbalance de clases**
El dataset tiene clases desbalanceadas en ‚ÄúAttrition‚Äù (s√≠/no).  
Se usa `imblearn` (por ejemplo `RandomUnderSampler`) para equilibrarlas antes del entrenamiento.

---

### **Paso 6 ‚Äî Entrenamiento de modelos**
Se entrenan y comparan distintos modelos de machine learning, como:
- `LogisticRegression`
- `KNeighborsClassifier`
- `GaussianNB`
- `RandomForestClassifier`
- `GradientBoostingClassifier`
- `SVC`
- `MLPClassifier`

Cada uno se eval√∫a con m√©tricas como:
- `accuracy_score`
- `f1_score`
- `roc_auc_score`
- `confusion_matrix`

---

### **Paso 7 ‚Äî Evaluaci√≥n y comparaci√≥n de resultados**
Se grafican o muestran tablas comparativas con el rendimiento de cada modelo.  
Tambi√©n se pueden mostrar curvas ROC y matrices de confusi√≥n.

---

### **Paso 8 ‚Äî Exportaci√≥n de resultados**
Si el notebook genera resultados (por ejemplo, empleados con alto riesgo de renuncia), estos se guardan en CSV:

```python
df_empleados_riesgo.to_csv("outputs/empleados_en_riesgo.csv", index=False)
```

Si no existe la carpeta `outputs/`, crearla antes:

```python
from pathlib import Path
Path("outputs").mkdir(exist_ok=True)
```

---

### **Paso 9 ‚Äî Conclusiones**
Al final del notebook se presentan conclusiones generales del an√°lisis y del modelo con mejor desempe√±o.
